---
title: "Scenario 2: Competition"
output: html_document
---

```{r setup, include=FALSE}
# libraries
require(kableExtra)
require(tidyverse)
require(mgcv)
require(errors)

# chunk params
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# set ggplot theme
theme_set(theme_linedraw() + theme(panel.grid = element_blank()) + theme(legend.position = "none"))

# set seed for randomization
set.seed(12)
```

```{r setup-functions}
## GENERAL USE FUNCTIONS ## ----------------------------------------------------

# function to repeat vector as rows of a matrix
rep.row <- function(x,n){matrix(rep(x, each = n), nrow = n)}

## SIMULATION FUNCTIONS ## -----------------------------------------------------

# function to wrangle simulation results into long format 
pops_long <- function(pops_df, n = n_pairs, g = steps, set_id) {
  pops_df = as.data.frame(pops_df)
  colnames(pops_df) = as.character(1:steps)
  pops_df = mutate(.data = pops_df, "popID" = paste(set_id, sprintf("pop%s", 1:n), sep = "-")) %>%
    pivot_longer(cols = 1:all_of(g), names_to = "time", values_to = "N") %>%
    separate(popID, into = c("set", "pop"), sep = "-", remove = FALSE) %>%
    mutate_at(vars(time), as.integer)
}

# function to simulate populations according to Lotka-Volterra competition model
sim <- function(Ni_init = N0i, Nj_init = N0j, n_pairedpops = n_pairs, timesteps = steps, Ri = r_i_error, Rj = r_j_error, int_ij = alpha_ij, int_ji = alpha_ji, proc = proc_error, K){
  
  # initialize matrix to store results (population sizes)
  Ni <- as.matrix(rep(Ni_init, n_pairedpops))
  Nj <- as.matrix(rep(Nj_init, n_pairedpops))
  
  # Nt+1_i = Nt_i + rNt_i * ((1 - Nt_i/K_i) + alpha_ji*Nt_j/K_j
  # calculate population sizes
  for(t in 2:timesteps-1){
    
    # population i
    temp_i = Ni[t]*(1 + Ri[,t]*(1 - (Ni[t] + int_ij*Nj[t])/K[t])) + proc[,t]
    temp_i[which(temp_i < 0)] <- 0 # assign 0 to negative population sizes
    Ni <- cbind(Ni, temp_i) # append resulting population size to results vector
    
    # population j
    temp_j = Nj[t]*(1 + Rj[,t]*(1 - (Nj[t] + int_ji*Ni[t])/K[t])) + proc[,t]
    temp_j[which(temp_j < 0)] <- 0 # assign 0 to negative population sizes
    Nj <- cbind(Nj, temp_j) # append resulting population size to results vector
  }

  # wrangle!
  time <- 1:timesteps   # create vector of time values for plotting
  # bind together
  N = rbind(pops_long(Ni, set_id = "i"), pops_long(Nj, set_id = "j"))

return(N)
}

# plot simulated populations
sim_plot <- function(df, K_slope, K_int, title){
  ggplot(df) +
  geom_line(aes(x = time, y = N, group = popID, col = popID)) + 
  geom_abline(slope = K_slope, intercept = K_int, lty = 2, lwd = .6) + 
  facet_wrap(~ set) + 
  ylim(c(0, K_int*2)) +
  ggtitle(title)
}

# calculate and plot covariation and correlation heatmaps
covcor_pops <- function(df_long){
  # convert to wide
  temp_w <- subset(df_long, select = -c(set, pop)) %>%
    pivot_wider(names_from = popID, values_from = N, id_cols = time) %>%
    subset(select = -time)
  # calculate and plot covariance
  cov_res <- cov(temp_w) %>% as.data.frame() %>% mutate(population_j = rownames(.)) %>%
    pivot_longer(cols = 1:(ncol(.)-1), names_to = "population_i") 
  # keep rows of i vs. j only (not i vs. i or j vs. j)
  cov_res = cov_res[-grep("i-", cov_res$population_j),]
  cov_res = cov_res[-grep("j-", cov_res$population_i),]
  # plot heatmap
  p1 <- ggplot(data = cov_res, aes(x = population_j, y = population_i)) +
    geom_tile(aes(fill = value)) + scale_fill_viridis_c() +
    labs(y = "", x = "", fill = "Covariation") + theme(legend.position = "right")
  
  # calculate and plot correlation
  cor_res <- cor(temp_w) %>% as.data.frame() %>% mutate(population_j = rownames(.)) %>%
    pivot_longer(cols = 1:(ncol(.)-1), names_to = "population_i")
  # keep rows of i vs. j only (not i vs. i or j vs. j)
  cor_res = cor_res[-grep("i-", cor_res$population_j),]
  cor_res = cor_res[-grep("j-", cor_res$population_i),]

    # plot heatmap
  p2 <- ggplot(data = cor_res, aes(x = population_j, y = population_i)) +
    geom_tile(aes(fill = value)) + scale_fill_viridis_c() + 
     labs(y = "", x = "", fill = "Correlation") + theme(legend.position = "right")
  return(list(p1, p2))
}


## LPI FUNCTIONS ## ------------------------------------------------------------

calclpi_exp <- function(Ni_init = N0i, Nj_init = N0j, n_pairedpops = 1, timesteps = steps, Ri = r_i, Rj = r_j, int_ij = alpha_ij, int_ji = alpha_ji, K){
  
  # initialize vector to store results (population sizes)
  Ni <- Ni_init
  Nj <- Nj_init
  
  # Nt+1_i = Nt_i + rNt_i * ((1 - Nt_i/K_i) + alpha_ji*Nt_j/K_j
  # calculate population sizes
  for(t in 2:timesteps){
    
    # population i
    temp_i = Ni[t-1]*(1 + Ri[1,t]*(1 - (Ni[t-1] + int_ij*Nj[t-1])/K[t]))
    temp_i[which(temp_i < 0)] <- 0 # assign 0 to negative population sizes
    Ni <- cbind(Ni, temp_i) # append resulting population size to results vector
    
    # population j
    temp_j = Nj[t-1]*(1 + Rj[1,t]*(1 - (Nj[t-1] + int_ji*Ni[t-1])/K[t]))
    temp_j[which(temp_j < 0)] <- 0 # assign 0 to negative population sizes
    Nj <- cbind(Nj, temp_j) # append resulting population size to results vector
  }

   # initialize df to store dts
  lambda_df = data.frame(dt_i = 0, dt_j = 0)
  for(i in 2:steps){
    # calculate dt
    lambda_df[i, "dt_i"] = log10(Ni[i]/Ni[i-1])
    lambda_df[i, "dt_j"] = log10(Nj[i]/Nj[i-1])
  }
  # take geometric mean
  lambda_gm <- apply(10^(lambda_df), 1, gm_mean)
  
  # calculate LPI
  lpi_exp <- data.frame(time = 1:steps, LPI = calclpi(log10(lambda_gm)))
  
  return(list("Ni" = Ni, "Nj" = Nj, "dt" = lambda_df, "dt_mean" = lambda_gm, "lpi" = lpi_exp))
}


# function to run GAM on population time series + predict over all time steps
gam_lpi <- function(pops){
  
  # estimate the smoothing parameter to be half the time series length
  smoothParm = round(length(unique(pops$time))/2)
  
  # transform population sizes
  pops$N <- log10(pops$N + 1)
  # wrangle into wide format
  pops_w = pivot_wider(data = pops, id_cols = time, names_from = popID, values_from = N) %>%
    mutate_at(vars(time), as.integer) %>% as.matrix()
  
  # run GAM (modified code from CalcLPI function in rlpi package)
  m <- list()
  for(i in 2:ncol(pops_w)){
    N <- as.vector(pops_w[,i])
    time <- as.vector(pops_w[,"time"])
    m[[i-1]] <- gam(N ~ s(time, k = smoothParm), 
                    family = gaussian(), fx = TRUE, method = "REML")
  }
  names(m) <- unique(pops$popID)
  
  # predict over time period
  pred_ls = lapply(m, predict.gam, type = "response", se.fit = TRUE)
  
  # wrangle into one long format dataframe
  pred = pred_ls %>%
    lapply(bind_cols) %>%
    lapply(mutate, time = pops_w[,"time"]) %>%
    bind_rows(.id = "popID")
  # join to observation dataframe
  pred = full_join(pops, pred, by = c("popID", "time"))
  
  return(pred)
}


# function to calculate dt from GAM predictions
get_dt <- function(gam.pred_ls, time){
  # gam.pred_ls: list of predictions from GAMs (one per population)

  # extract predicted population size values
  N = gam.pred_ls$fit 
  # assign errors to values for propagation
  errors(N) = gam.pred_ls$se.fit
  # un-log10
  N = 10^N # un-log
  
  # initialize df to store dts
  dt_df = data.frame(time = time, dt = NA, se = NA)
  for(i in 2:length(N)){
    # calculate dt
    dt = log10(N[i]/N[i-1])
    dt_df[i, "dt"] = dt # save in the table
    # save propagated error 
    dt_df[i, "se"] = unlist(errors(dt))
  }
  return("dt" = dt_df)
}

# geometric mean function
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

# function to calculate geometric mean that will be used in bootstrapping
geoMean_boot <- function(dt, i){
  d <- dt[i] # indexing happens here
  avg <- gm_mean(d, na.rm = TRUE)
  return(avg)
}

# function for bootstrap confidence interval 
dt_boot = function(dt){
  # bootstrap resampling
  dt_r = boot::boot(dt, statistic = geoMean_boot, R = 1000)
  # calculate 95% confidence intervals
  dt_ci = boot::boot.ci(dt_r, type = "basic", R = 1000)
  # wrangle into table for output
  dtboot_df = data.frame(gm = dt_ci$t0, cilo = dt_ci$basic[4], cihi = dt_ci$basic[5])
  return(dtboot_df)
}

# function to calculate LPI from mean dt
calclpi <- function(dt){
  # calculate index value
  lpi = c(1) # initial value is 1 
  for(i in 2:length(dt)){
    lpi[i] <- lpi[i-1]*10^dt[i] }
  return(lpi)
}
```


## Mechanistic simulation

Populations will be simulated using a mechanistic approach according to a discrete Lotka-Volterra competition model.

In its simplest form, each population's size will vary according to:

$$N_i(t+1) = N_i(t) + \lambda_i * N_i(t)$$
where $N_i$ is the size of population $i$, $t$ is each time step, and $\lambda$ is the true growth rate of population $i$.

The true growth rate is determined by:

$$ \lambda_i = r*(1-\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i})$$
where:  
$r$ is population $i$'s maximum growth rate  
$\alpha_{ji}$ is the interaction effect of population $j$ on population $i$  
$N_j$ is the size of population $j$  
$K_i$ is the carrying capacity of population $i$  

#### Scenarios of population change

The largest threat to populations in the Living Planet Index is habitat degradation and loss. For this experiment, I will be changing the carrying capacity as a way to mimick habitat loss/degradation, in order to generate three possible populations trends:

- growing ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} < 1$) 

- stable  ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} = 1$)  

- declining  ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} > 1$)  

```{r illustrate-K-scenarios}
# create palette
pal <- c("#24a015", "#1524a0", "#a01524")

# blank plot
par(mar = c(5.1, 4.1, 2.5, 2))
plot(1, type="n", xlab="time", main = "Population trend scenarios",
     ylab="Carrying capacity (K)", xlim=c(0.35, 10), ylim=c(-1, 1), las = 1, yaxt='n')
axis(side = 2, 0, labels = "", las = 1)
abline(a = 0, b = 0.1, col = pal[1], lwd = 2) # growing
abline(h = 0, col = pal[2], lwd = 2) # stable
abline(a = 0, b = -0.1, col = pal[3], lwd = 2) # declining
legend("topleft", legend = c("growing", "stable", "declining"), 
       col = pal, lty = 1, lwd = 2, horiz = TRUE, inset = .03)
text(x = 9.2, y = 0, pos = 3, labels = "N0 = K")
```

#### Source of covariation

Populations will be generated as antagonistic interaction partners, meaning the growth of one population will negatively impact the growth of its paired population (and vice-versa). I'm making this choice because this type of covariation reflects competition (directly, as the Lotka-Volterra equation is for this), which is likely to be prevalent in the Living Planet Database.

#### Sources of error

Population time series are subject to both observation error (i.e. "noisy" measurements of population size), and process error (i.e. environmental noise, demographic stochasticity, and other "noise" introduced into the processes that govern population size).

**[ fill later ]**

## Scenario 1

This first scenario is a "perfect world" scenario, where there are no random fluctuations in growth rate from population dynamics or environmental stochasticity (process errors), observation errors, or changing biotic conditions (interactions do not influence the populations).

The purpose is to see how the LPI detects declines, stability, and growth in population size, to detect any inherent bias in its estimation of the true population growth rate (i.e. $\lambda$), without any introduced error.

```{r plot-scenario, eval = FALSE}
# create palette
pal <- c("#24a015", "#1524a0", "#a01524")

# growth rate
plot(1, type="n", xlab="time", main = "Scenario 1: Constant growth rate",
     ylab=expression(lambda), xlim=c(0, 10), ylim=c(-1, 1), las = 1)
abline(h = 0.5, col = pal[1], lwd = 2)
abline(h = 0, col = pal[2], lwd = 2)
abline(h = -0.5, col = pal[3], lwd = 2)
legend("top", legend = c("growing", "stable", "declining"), 
       col = pal, lty = 1, lwd = 2, horiz = TRUE, inset = .03)
```

The parameters used to simulate population fluctuations using the equations above will be:

```{r set-parameters}
## BASIC SET-UP ##

# number of population pairs to generate
n_pairs = 10

# number of generations
steps = 10 

## POPULATION DYNAMICS ##

# initial population sizes
N0i = 190
N0j = 190

# growth rate
r_i = matrix(1, nrow = n_pairs, ncol = steps)
r_j = matrix(1, nrow = n_pairs, ncol = steps)

# interaction coefficients (competition)
alpha_ij = 0.2
alpha_ji = 0.1

## CARRYING CAPACITY SCENARIOS ##
K_increase = 200 + 10*c(0:(steps-1))
K_stable = rep(200, steps)
K_decline = 200 - 10*c(0:(steps-1))

## ERROR ##

# generate error
# process error (environmental noise)
proc_error = matrix(runif(n_pairs*steps, -N0i/10, N0i/10), nrow = n_pairs, ncol = steps)
# observation error
observation = matrix(runif(n_pairs*steps, -0.1, 0.1), nrow = n_pairs, ncol = steps) 

# add observation error to growth rates
r_i_error = r_i + observation
r_j_error = r_j + observation
```

```{r params-table}
params <- data.frame("i" = c(N0i, r_i[1,1], alpha_ji, 
                             paste0("+/-", 0.1), 
                             paste0("+/-", N0i/10)), 
                     "j" = c(N0j, r_j[1,1], alpha_ji, 
                             paste0("+/-", 0.1), 
                             paste0("+/-", N0j/10)),
                     row.names = c("Initial size ($N0$)",
                                   "Maximum growth rate ($r$)",
                                   "Interaction effect ($\\alpha$)",
                                   "Observation error",
                                   "Process error"))
kbl(params, booktabs = TRUE, caption = "Simulation parameters") %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

## Simulation

### The simulated populations

```{r run-simulation}
N_stable <- sim(K = K_stable)
N_increase <- sim(K = K_increase)
N_decline <- sim(K = K_decline)

# save outputs!
saveRDS(list("N_increase" = N_increase,"N_stable" = N_stable,"N_decline" = N_decline),"~/Documents/GitHub/LPI-sensitivity/simulations/scenario2.RDS")
```

```{r plot-simulations, fig.show="hold", fig.height = 3}
sim_plot(df = N_decline, K_slope = -10, K_int = 200, 
         title = "Scenario A: Declining habitat, declining competitors")
sim_plot(df = N_stable, K_slope = 0, K_int = 200, 
         title = "Scenario B: Stable habitat, stable competitors")
sim_plot(df = N_increase, K_slope = 10, K_int = 200, 
         title = "Scenario C: Growing habitat, growing competitors")
```

### Covariance & correlation structures

#### Scenario A: Declining habitat, declining competitors
```{r covariance-correlation-heatmaps-sce1, fig.show="hold", out.width='50%'}
temp <- invisible(covcor_pops(N_decline))
temp[[1]]
temp[[2]]
```

#### Scenario B: Stable habitat, stable competitors
```{r covariance-correlation-heatmaps-sce2, fig.show="hold",  out.width='50%'}
temp <- invisible(covcor_pops(N_stable))
temp[[1]]
temp[[2]]
```

#### Scenario C: Growing habitat, growing competitors
```{r covariance-correlation-heatmaps-sce3, fig.show="hold",  out.width='50%'}
temp <- invisible(covcor_pops(N_increase))
temp[[1]]
temp[[2]]
```


## Living Planet Index

#### Expected LPI

The true value of the LPI was calculated by generating populations with the same parameters outlined about, but without process and observation error. Instead of passing these populations through a GAM to generate predicted values on which the growth rate is calculated as in the LPI, growth rates are directly calculated from the population size changes between time steps. 

The "observed" LPI will be compared against this true value later in the document to measure the accuracy and precision of the LPI in detecting these trends.

```{r expected-values}
# calculate expected values for each step of the way!
lpi_exp_decline = calclpi_exp(K = K_decline)
lpi_exp_stable = calclpi_exp(K = K_stable)
lpi_exp_increase = calclpi_exp(K = K_increase)
# bind results into one
lpi_exp <- rbind(
  mutate(lpi_exp_decline$lpi, scenario = "Scenario A: Decline"),
  mutate(lpi_exp_stable$lpi, scenario = "Scenario B: Stable"),
  mutate(lpi_exp_increase$lpi, scenario = "Scenario C: Increase")
)
lpi_exp$scenario = factor(lpi_exp$scenario, levels = c("Scenario A: Decline", "Scenario B: Stable", "Scenario C: Increase"))

# plot!
ggplot(lpi_exp) +
  geom_line(aes(x = time, y = LPI, col = scenario)) +
  ylim(0,2) + labs(col = "") + theme(legend.position = "right")
```


#### Observed LPI

```{r gam}
# run GAM on each population time series and predict over all time steps
# (while storing the standard error from the GAM fit)
pred_decline <- gam_lpi(N_decline) 
pred_stable <- gam_lpi(N_stable) %>% invisible()
pred_increase <- gam_lpi(N_increase) %>% invisible()
```

```{r calculate-dt}
# split datasets into list of populations
pred_decline_ls <- split(pred_decline, f = pred_decline$popID)
pred_stable_ls <- split(pred_stable, f = pred_stable$popID)
pred_increase_ls <- split(pred_increase, f = pred_increase$popID)

# calculate dt from GAM predictions
dt_decline <- lapply(pred_decline_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario A: Decline") 
dt_stable <- lapply(pred_stable_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario B: Stable")
dt_increase <- lapply(pred_increase_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario C: Increase")

# join to observations dataframe
dt_decline_df = full_join(N_decline, dt_decline, by = c("popID", "time"))
dt_stable_df = full_join(N_stable, dt_stable, by = c("popID", "time"))
dt_increase_df = full_join(N_increase, dt_increase, by = c("popID", "time"))
# bind together into one df
dt_df <- rbind(dt_decline_df, dt_stable_df, dt_increase_df) 
dt_df$scenario = factor(dt_df$scenario, levels = c("Scenario A: Decline", "Scenario B: Stable", "Scenario C: Increase"))

```

```{r plot-dt, eval=FALSE}
ggplot(data = na.omit(dt_df), aes(x = time, group = popID)) +
  geom_ribbon(aes(ymin = dt-se, ymax = dt+se, fill = pop), alpha = .2) +
  geom_line(aes(y=dt), lwd = .2) + 
  facet_wrap(~scenario) + 
  labs(y = "Growth rate (log10)", title = "Population growth rates",
       col = "Paired \npopulations", fill = "Paired \npopulations",
       caption = "Ribbon shows propagated standard error from GAM predictions.")
```

```{r calculate-mean-growthrate}
# calculate geometric mean growth rate with 95% CI from bootstrapping

# decline
dt_gm_decline <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_decline_df$time))){
  dt_v = dt_decline_df[which(dt_decline_df$time == t), "dt"] %>% na.omit()
  dt_gm_decline[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_decline = bind_rows(dt_gm_decline) %>% log10()

# stable
dt_gm_stable <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_stable_df$time))){
  dt_v = dt_stable_df[which(dt_stable_df$time == t), "dt"] %>% na.omit()
  dt_gm_stable[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_stable = bind_rows(dt_gm_stable) %>% log10()

# increase
dt_gm_increase <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_increase_df$time))){
  dt_v = dt_increase_df[which(dt_increase_df$time == t), "dt"] %>% na.omit()
  dt_gm_increase[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_increase = bind_rows(dt_gm_increase) %>% log10()
```

```{r calculate-lpi}
# calculate LPI with bootstrapped 95%CI

# decline
lpi_decline <- data.frame(
    time = 1:nrow(dt_gm_decline), 
    LPI_boot = calclpi(dt_gm_decline$gm),
    cilo_boot = calclpi(dt_gm_decline$cilo),
    cihi_boot = calclpi(dt_gm_decline$cihi)
  )

# stable
lpi_stable <- data.frame(
    time = 1:nrow(dt_gm_stable), 
    LPI_boot = calclpi(dt_gm_stable$gm),
    cilo_boot = calclpi(dt_gm_stable$cilo),
    cihi_boot = calclpi(dt_gm_stable$cihi)
  )

# increase
lpi_increase <- data.frame(
    time = 1:nrow(dt_gm_increase), 
    LPI_boot = calclpi(dt_gm_increase$gm),
    cilo_boot = calclpi(dt_gm_increase$cilo),
    cihi_boot = calclpi(dt_gm_increase$cihi)
  )

# bind together
lpi <- rbind(
  mutate(lpi_decline, scenario = "Scenario A: Decline"),
  mutate(lpi_stable, scenario = "Scenario B: Stable"),
  mutate(lpi_increase, scenario = "Scenario C: Increase")
)
lpi$scenario = factor(lpi$scenario, 
                      levels = c("Scenario A: Decline", 
                                 "Scenario B: Stable", "Scenario C: Increase"))
```

```{r plot-lpi}
# Plot LPI with bootstrapped 95%CI  ------------
ggplot(lpi, aes(x = time)) +
  # bootstrap version
  geom_ribbon(aes(ymin = cilo_boot, ymax = cihi_boot, fill = scenario), alpha = .5) +
  geom_line(aes(y = LPI_boot)) +
  geom_line(data = lpi_exp, aes(x = time, y = LPI), lty = 2) +
  facet_wrap(~scenario) +
  labs(y = "Living Planet Index")
```

#### LPI Sensitivity

```{r calculate-accuracy-precision}
lpi$accuracy = lpi$LPI_boot - lpi_exp$LPI
lpi$precision = lpi$cihi_boot - lpi$cilo_boot

# get mean per scenario
sensitivity_means <- lpi %>% filter(time > 1) %>% # ignore first time step, because it's set to 1.
  group_by(scenario) %>%
  summarise(mean_accuracy = mean(accuracy),
            sd_accuracy = sd(accuracy))
```

```{r plot-sensitivity}
ggplot(sensitivity_means, aes(x = scenario)) +
  geom_errorbar(aes(ymin = mean_accuracy - sd_accuracy,
                    ymax = mean_accuracy + sd_accuracy), width = .1) +
  geom_point(aes(y = mean_accuracy), size = 2.5) +
  geom_hline(yintercept = 0, lty = 2) +
  labs(x = "", y = "Accuracy of the LPI") +
  ylim(-.5,.5)
```

```{r save-result}
saveRDS(lpi, "~/Documents/GitHub/LPI-sensitivity/outputs/scenario2_lpi.RDS")
```

