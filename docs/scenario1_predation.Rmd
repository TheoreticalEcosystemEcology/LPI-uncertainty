---
title: "Scenario 1: Constant growth rate"
output: html_document
---

```{r setup, include=FALSE}
# libraries
require(kableExtra)
require(tidyverse)
require(mgcv)
require(errors)

# chunk params
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)

# set ggplot theme
theme_set(theme_linedraw() + theme(panel.grid = element_blank()) + theme(legend.position = "none"))

# set seed for randomization
set.seed(12)
```

```{r setup-functions}
source('~/Documents/GitHub/LPI-sensitivity/scripts/scenario_functions.R')
```


## Mechanistic simulation

Populations will be simulated using a mechanistic approach according to a discrete Lotka-Volterra competition model.

In its simplest form, each population's size will vary according to:

$$N_i(t+1) = N_i(t) + \lambda_i * N_i(t)$$
where $N_i$ is the size of population $i$, $t$ is each time step, and $\lambda$ is the true growth rate of population $i$.

The true growth rate is determined by:

$$ \lambda_i = r*(1-\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i})$$
where:  
$r$ is population $i$'s maximum growth rate  
$\alpha_{ji}$ is the interaction effect of population $j$ on population $i$  
$N_j$ is the size of population $j$  
$K_i$ is the carrying capacity of population $i$  

#### Scenarios of population change

The largest threat to populations in the Living Planet Index is habitat degradation and loss. For this experiment, I will be changing the carrying capacity as a way to mimick habitat loss/degradation, in order to generate three possible populations trends:

- growing ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} < 1$) 

- stable  ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} = 1$)  

- declining  ($\frac{(N_i(t) + \alpha_{ji}N_j(t))}{K_i} > 1$)  

```{r illustrate-K-scenarios}
# create palette
pal <- c("#24a015", "#1524a0", "#a01524")

# blank plot
par(mar = c(5.1, 4.1, 2.5, 2))
plot(1, type="n", xlab="time", main = "Population trend scenarios",
     ylab="Carrying capacity (K)", xlim=c(0.35, 10), ylim=c(-1, 1), las = 1, yaxt='n')
axis(side = 2, 0, labels = "", las = 1)
abline(a = 0, b = 0.1, col = pal[1], lwd = 2) # growing
abline(h = 0, col = pal[2], lwd = 2) # stable
abline(a = 0, b = -0.1, col = pal[3], lwd = 2) # declining
legend("topleft", legend = c("growing", "stable", "declining"), 
       col = pal, lty = 1, lwd = 2, horiz = TRUE, inset = .03)
text(x = 9.2, y = 0, pos = 3, labels = "N0 = K")
```

#### Source of covariation

Populations will be generated as antagonistic interaction partners, meaning the growth of one population will negatively impact the growth of its paired population (and vice-versa). I'm making this choice because this type of covariation reflects competition (directly, as the Lotka-Volterra equation is for this), which is likely to be prevalent in the Living Planet Database.

#### Sources of error

Population time series are subject to both observation error (i.e. "noisy" measurements of population size), and process error (i.e. environmental noise, demographic stochasticity, and other "noise" introduced into the processes that govern population size).

**[ fill later ]**

## Scenario 1

This first scenario is a "perfect world" scenario, where there are no random fluctuations in growth rate from population dynamics or environmental stochasticity (process errors), observation errors, or changing biotic conditions (interactions do not influence the populations).

The purpose is to see how the LPI detects declines, stability, and growth in population size, to detect any inherent bias in its estimation of the true population growth rate (i.e. $\lambda$), without any introduced error.

```{r plot-scenario, eval = FALSE}
# create palette
pal <- c("#24a015", "#1524a0", "#a01524")

# growth rate
plot(1, type="n", xlab="time", main = "Scenario 1: Constant growth rate",
     ylab=expression(lambda), xlim=c(0, 10), ylim=c(-1, 1), las = 1)
abline(h = 0.5, col = pal[1], lwd = 2)
abline(h = 0, col = pal[2], lwd = 2)
abline(h = -0.5, col = pal[3], lwd = 2)
legend("top", legend = c("growing", "stable", "declining"), 
       col = pal, lty = 1, lwd = 2, horiz = TRUE, inset = .03)
```

The parameters used to simulate population fluctuations using the equations above will be:

```{r set-parameters}
## BASIC SET-UP ##

# number of population pairs to generate
n_pairs = 10

# number of generations
steps = 10 

## POPULATION DYNAMICS ##

# initial population sizes
N0i = 200
N0j = 200

# growth rate
r_i = matrix(1, nrow = n_pairs, ncol = steps)
r_j = matrix(1, nrow = n_pairs, ncol = steps)

# interaction coefficients (competition)
alpha_ij = -0.2
alpha_ji = 0.2

## CARRYING CAPACITY SCENARIOS ##
K_increase = 200 + 10*c(0:(steps-1))
K_stable = rep(200, steps)
K_decline = 200 - 10*c(0:(steps-1))

## ERROR ##

# generate error
# process error (environmental noise)
proc_error = matrix(runif(n_pairs*steps, -N0i/10, N0i/10), nrow = n_pairs, ncol = steps)
# observation error
observation = matrix(runif(n_pairs*steps, -0.1, 0.1), nrow = n_pairs, ncol = steps) 

# add observation error to growth rates
r_i_error = r_i + observation
r_j_error = r_j + observation
```

```{r params-table}
params <- data.frame("i" = c(N0i, r_i[1,1], alpha_ji, 
                             paste0("+/-", 0.1), 
                             paste0("+/-", N0i/10)), 
                     "j" = c(N0j, r_j[1,1], alpha_ji, 
                             paste0("+/-", 0.1), 
                             paste0("+/-", N0j/10)),
                     row.names = c("Initial size ($N0$)",
                                   "Maximum growth rate ($r$)",
                                   "Interaction effect ($\\alpha$)",
                                   "Observation error",
                                   "Process error"))
kbl(params, booktabs = TRUE, caption = "Simulation parameters") %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

## Simulation

### The simulated populations

```{r run-simulation}
N_stable <- sim(K = K_stable)
N_increase <- sim(K = K_increase)
N_decline <- sim(K = K_decline)

# save outputs!
saveRDS(list("N_increase" = N_increase,"N_stable" = N_stable,"N_decline" = N_decline),"~/Documents/GitHub/LPI-sensitivity/simulations/scenario1.RDS")
```

```{r plot-simulations, fig.show="hold", fig.height = 3}
sim_plot(df = N_decline, K_slope = -10, K_int = 200, 
         title = "Scenario A: Declining habitat, declining competitors")
sim_plot(df = N_stable, K_slope = 0, K_int = 200, 
         title = "Scenario B: Stable habitat, stable competitors")
sim_plot(df = N_increase, K_slope = 10, K_int = 200, 
         title = "Scenario C: Growing habitat, growing competitors")
```

### Covariance & correlation structures

#### Scenario A: Declining habitat, declining competitors
```{r covariance-correlation-heatmaps-sce1, fig.show="hold", out.width='50%'}
invisible(covcor_pops(N_decline))
```

#### Scenario B: Stable habitat, stable competitors
```{r covariance-correlation-heatmaps-sce2, fig.show="hold",  out.width='50%'}
invisible(covcor_pops(N_stable))
```

#### Scenario C: Growing habitat, growing competitors
```{r covariance-correlation-heatmaps-sce3, fig.show="hold",  out.width='50%'}
invisible(covcor_pops(N_increase))
```


## Living Planet Index

#### Expected LPI

The true value of the LPI was calculated by generating populations with the same parameters outlined about, but without process and observation error. Instead of passing these populations through a GAM to generate predicted values on which the growth rate is calculated as in the LPI, growth rates are directly calculated from the population size changes between time steps. 

The "observed" LPI will be compared against this true value later in the document to measure the accuracy and precision of the LPI in detecting these trends.

```{r expected-values}
# calculate expected values for each step of the way!
lpi_exp_decline = calclpi_exp(K = K_decline)
lpi_exp_stable = calclpi_exp(K = K_stable)
lpi_exp_increase = calclpi_exp(K = K_increase)
# bind results into one
lpi_exp <- rbind(
  mutate(lpi_exp_decline$lpi, scenario = "Scenario A: Decline"),
  mutate(lpi_exp_stable$lpi, scenario = "Scenario B: Stable"),
  mutate(lpi_exp_increase$lpi, scenario = "Scenario C: Increase")
)
lpi_exp$scenario = factor(lpi_exp$scenario, levels = c("Scenario A: Decline", "Scenario B: Stable", "Scenario C: Increase"))

# plot!
ggplot(lpi_exp) +
  geom_line(aes(x = time, y = LPI, col = scenario)) +
  ylim(0,2) + labs(col = "") + theme(legend.position = "right")
```


#### Observed LPI

```{r gam}
# run GAM on each population time series and predict over all time steps
# (while storing the standard error from the GAM fit)
pred_decline <- gam_lpi(N_decline)
pred_stable <- gam_lpi(N_stable)
pred_increase <- gam_lpi(N_increase)
```

```{r calculate-dt}
# split datasets into list of populations
pred_decline_ls <- split(pred_decline, f = pred_decline$popID)
pred_stable_ls <- split(pred_stable, f = pred_stable$popID)
pred_increase_ls <- split(pred_increase, f = pred_increase$popID)

# calculate dt from GAM predictions
dt_decline <- lapply(pred_decline_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario A: Decline")
dt_stable <- lapply(pred_stable_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario B: Stable")
dt_increase <- lapply(pred_increase_ls, get_dt, time = 1:steps) %>% 
  bind_rows(.id = "popID") %>% mutate(scenario = "Scenario C: Increase")

# join to observations dataframe
dt_decline_df = full_join(N_decline, dt_decline, by = c("popID", "time"))
dt_stable_df = full_join(N_stable, dt_stable, by = c("popID", "time"))
dt_increase_df = full_join(N_increase, dt_increase, by = c("popID", "time"))
# bind together into one df
dt_df <- rbind(dt_decline_df, dt_stable_df, dt_increase_df) 
dt_df$scenario = factor(dt_df$scenario, levels = c("Scenario A: Decline", "Scenario B: Stable", "Scenario C: Increase"))

```

```{r plot-dt, eval=FALSE}
ggplot(data = na.omit(dt_df), aes(x = time, group = popID)) +
  geom_ribbon(aes(ymin = dt-se, ymax = dt+se, fill = pop), alpha = .2) +
  geom_line(aes(y=dt), lwd = .2) + 
  facet_wrap(~scenario) + 
  labs(y = "Growth rate (log10)", title = "Population growth rates",
       col = "Paired \npopulations", fill = "Paired \npopulations",
       caption = "Ribbon shows propagated standard error from GAM predictions.")
```

```{r calculate-mean-growthrate}
# calculate geometric mean growth rate with 95% CI from bootstrapping

# decline
dt_gm_decline <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_decline_df$time))){
  dt_v = dt_decline_df[which(dt_decline_df$time == t), "dt"] %>% na.omit()
  dt_gm_decline[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_decline = bind_rows(dt_gm_decline) %>% log10()

# stable
dt_gm_stable <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_stable_df$time))){
  dt_v = dt_stable_df[which(dt_stable_df$time == t), "dt"] %>% na.omit()
  dt_gm_stable[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_stable = bind_rows(dt_gm_stable) %>% log10()

# increase
dt_gm_increase <- list(data.frame(gm = 1, cilo = 1, cihi = 1))
for(t in 2:length(unique(dt_increase_df$time))){
  dt_v = dt_increase_df[which(dt_increase_df$time == t), "dt"] %>% na.omit()
  dt_gm_increase[[t]] = dt_boot(10^dt_v$dt) 
}
dt_gm_increase = bind_rows(dt_gm_increase) %>% log10()
```

```{r calculate-lpi}
# calculate LPI with bootstrapped 95%CI

# decline
lpi_decline <- data.frame(
    time = 1:nrow(dt_gm_decline), 
    LPI_boot = calclpi(dt_gm_decline$gm),
    cilo_boot = calclpi(dt_gm_decline$cilo),
    cihi_boot = calclpi(dt_gm_decline$cihi)
  )

# stable
lpi_stable <- data.frame(
    time = 1:nrow(dt_gm_stable), 
    LPI_boot = calclpi(dt_gm_stable$gm),
    cilo_boot = calclpi(dt_gm_stable$cilo),
    cihi_boot = calclpi(dt_gm_stable$cihi)
  )

# increase
lpi_increase <- data.frame(
    time = 1:nrow(dt_gm_increase), 
    LPI_boot = calclpi(dt_gm_increase$gm),
    cilo_boot = calclpi(dt_gm_increase$cilo),
    cihi_boot = calclpi(dt_gm_increase$cihi)
  )

# bind together
lpi <- rbind(
  mutate(lpi_decline, scenario = "Scenario A: Decline"),
  mutate(lpi_stable, scenario = "Scenario B: Stable"),
  mutate(lpi_increase, scenario = "Scenario C: Increase")
)
lpi$scenario = factor(lpi$scenario, 
                      levels = c("Scenario A: Decline", 
                                 "Scenario B: Stable", "Scenario C: Increase"))
```

```{r plot-lpi}
# Plot LPI with bootstrapped 95%CI  ------------
ggplot(lpi, aes(x = time)) +
  # bootstrap version
  geom_ribbon(aes(ymin = cilo_boot, ymax = cihi_boot, fill = scenario), alpha = .5) +
  geom_line(aes(y = LPI_boot)) +
  geom_line(data = lpi_exp, aes(x = time, y = LPI), lty = 2) +
  facet_wrap(~scenario) +
  labs(y = "Living Planet Index")
```

#### LPI Sensitivity

```{r calculate-accuracy-precision}
lpi$accuracy = lpi$LPI_boot - lpi_exp$LPI
lpi$precision = lpi$cihi_boot - lpi$cilo_boot

# get mean per scenario
sensitivity_means <- lpi %>% filter(time > 1) %>% # ignore first time step, because it's set to 1.
  group_by(scenario) %>%
  summarise(mean_accuracy = mean(accuracy),
            sd_accuracy = sd(accuracy))
```

```{r plot-sensitivity}
ggplot(sensitivity_means, aes(x = scenario)) +
  geom_errorbar(aes(ymin = mean_accuracy - sd_accuracy,
                    ymax = mean_accuracy + sd_accuracy), width = .1) +
  geom_point(aes(y = mean_accuracy), size = 2.5) +
  geom_hline(yintercept = 0, lty = 2) +
  labs(x = "", y = "Accuracy of the LPI") +
  ylim(-.5,.5)
```

```{r save-result}
saveRDS(lpi, "~/Documents/GitHub/LPI-sensitivity/outputs/scenario1_lpi.RDS")
```

